{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aplicação do modelo NLP aos tweets VIM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eikl8U_X3ZFW",
        "colab_type": "code",
        "outputId": "b1ebe2fb-46fc-4dd4-9050-63d3e5b6c381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE \n",
        "# Ano: 2019\n",
        "# Projeto: Virtual Mood Identifier\n",
        "# Autor: Alysson Rafael Oliveira de Lima\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "\n",
        "nltk.download('subjectivity')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "n_instances = 1000\n",
        "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
        "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Package subjectivity is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tqVEKOR4AHx",
        "colab_type": "code",
        "outputId": "eaa721d0-50f4-4530-adf7-fd9135291553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_subj_docs = subj_docs[:80]\n",
        "test_subj_docs = subj_docs[80:100]\n",
        "train_obj_docs = obj_docs[:80]\n",
        "test_obj_docs = obj_docs[80:100]\n",
        "training_docs = train_subj_docs+train_obj_docs\n",
        "testing_docs = test_subj_docs+test_obj_docs\n",
        "sentim_analyzer = SentimentAnalyzer()\n",
        "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n",
        "\n",
        "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
        "len(unigram_feats)\n",
        "\n",
        "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)\n",
        "\n",
        "training_set = sentim_analyzer.apply_features(training_docs)\n",
        "test_set = sentim_analyzer.apply_features(testing_docs)\n",
        "\n",
        "trainer = NaiveBayesClassifier.train\n",
        "classifier = sentim_analyzer.train(trainer, training_set)\n",
        "\n",
        "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
        "  print('{0}: {1}'.format(key, value))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training classifier\n",
            "Evaluating NaiveBayesClassifier results...\n",
            "Accuracy: 0.8\n",
            "F-measure [obj]: 0.8\n",
            "F-measure [subj]: 0.8\n",
            "Precision [obj]: 0.8\n",
            "Precision [subj]: 0.8\n",
            "Recall [obj]: 0.8\n",
            "Recall [subj]: 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTQHLAg54wVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/alyssonolima/Projeto-Virtual-Mood-Identifier/master/Dados/tweets_brutos.csv\")\n",
        "sentences = dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0H8KAvnJWRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "compo = []\n",
        "negative = []\n",
        "neutro = []\n",
        "pos = []\n",
        "\n",
        "#Monta os dados para gerar o csv\n",
        "for sentence in sentences:    \n",
        "    ss = sid.polarity_scores(sentence)    \n",
        "    compo.append(ss[\"compound\"])\n",
        "    negative.append(ss[\"neg\"])\n",
        "    neutro.append(ss[\"neu\"])\n",
        "    pos.append(ss[\"pos\"])\n",
        "    \n",
        "\n",
        "tweets_categorizados = pd.DataFrame({'tweets': sentences, 'compound': compo, 'negativos': negative, 'neutro': neutro, 'positivo':pos})\n",
        "tweets_categorizados.to_csv(\"tweets_categorizados.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}